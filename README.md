I'll create a comprehensive README file for the repository **How and When are High-Frequency Stock Returns Predictable?** This will include an overview of the project, installation and usage instructions, dataset details, methodologies, contributor information, and license details. I'll get back to you once it's ready.

# How and When are High-Frequency Stock Returns Predictable?

## Project Overview  
**How and When are High-Frequency Stock Returns Predictable?** is a research project exploring the predictability of ultra high-frequency stock returns (and the time between trades, or **durations**) using detailed market data and machine learning techniques ([EconPapers: How and When are High-Frequency Stock Returns Predictable?](https://econpapers.repec.org/RePEc:nbr:nberwo:30366#:~:text=Abstract%3A%20This%20paper%20studies%20the,data%20on%20a%20scale%20of)). This GitHub repository contains the replication code for that study, implementing the methodology on tick-level data for stocks in the HS300 index (CSI 300, a major Chinese stock index). This repository provides the code to reproduce the findings that **short-horizon stock returns can be predicted with meaningful accuracy using microstructure data**, identifying *when* (under what market conditions and timeframes) and *how* (with which features and models) such predictability arises.


## Installation Instructions  
To set up the environment and dependencies for this project, follow these steps:
- **Install Python Packages**: The code is written in Python and relies on several libraries. You can install the required packages using pip. For example:  
  ```bash
  pip install pandas numpy scikit-learn optuna lightgbm xgboost
  ```  
  This will install:  
  * **pandas** (for data manipulation)  
  * **numpy** (for numerical computations)  
  * **scikit-learn** (for machine learning models like Random Forests, Lasso, Ridge, MLP) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=from%20sklearn))  
  * **optuna** (for hyperparameter tuning) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=import%20optuna))  
  * **lightgbm** (LightGBM gradient boosting model) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=from%20xgboost%20import%20XGBRegressor))  
  * **xgboost** (XGBoost gradient boosting model) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=from%20xgboost%20import%20XGBRegressor))  
  Ensure these are installed before running the code. You may use a virtual environment or conda environment to manage dependencies.  
- **Prepare Data**: The high-frequency dataset is not included due to size and licensing constraints. You will need tick-by-tick trade and quote data for the relevant stocks. In the original study, the authors used the complete trades and quotes for 101 large-cap U.S. stocks (S&P 100 constituents) from Jan 2019 to Dec 2020 ([Movement of lower-priced stocks easier to predict for HFT firms, finds Princeton paper - IR Impact](http://www.ir-impact.com/2022/08/movement-lower-priced-stocks-easier-predict-hft-firms-finds-princeton-paper/#:~:text=For%20the%20research%2C%20the%20team,of%20March%20and%20April%202020%E2%80%99)). In this replication, the code expects data for stocks in the HS300 index (likely year 2020). Obtain the data from a market data provider or exchange, ensuring it includes every trade and quote update with timestamps. Once obtained, organize the data as expected by the code (see **Dataset Information** below for details).  
- **File Path Configuration**: Update file paths in the code if necessary. The code references directories like `../../data/HFData/HS300_data/` and `/data/work/yangsq/trainset_all/` for input/output. You may need to modify these paths to point to where your data is stored. For example, in `PreTrain.py` and other scripts, adjust the base directory to match your system’s file structure.  

After installing the libraries and setting up the data files, you should be ready to run the analysis code.

## Usage Guide  
This section explains how to use the provided code to replicate the analyses and results. The repository includes several Python scripts that correspond to different stages of the experiment:

1. **Data Preprocessing (Feature Construction)** – **`PreTrain.py`**:  
   This script reads raw tick data and constructs the predictor features and response variables. It implements the methodology for computing various microstructure features from the trade and quote data. For each stock (and each trading day), it calculates a wide range of predictors (see **Methodology** for details) and the corresponding short-horizon outcomes (future return and duration). Before running this, ensure your data files are in the expected folder structure. You might need to edit `PreTrain.py` to specify which stocks to process. By default, the code uses a list of representative stocks (e.g., 12 stock codes) for an initial pretraining step ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/PreTrain.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/PreTrain.py#:~:text=We%20choose%2012%20representative%20stocks,in%20HS300%20to%20pretrain)). Running this script will likely produce intermediate files (e.g., daily feature data stored as pickles in a `trainset_all/<stock>/` directory). To execute the script, run:  
   ```bash
   python PreTrain.py
   ```  
   *This will calculate all the predictor variables and save the processed dataset for the next steps.*  
2. **Model Training and Evaluation (Calendar Time)** – **`Train copy calendar.py`**:  
   This script trains prediction models on the constructed dataset using calendar time splitting (i.e., real time intervals). It loads the processed data (from the output of PreTrain), and then for each stock and each day, it builds models to predict short-term returns and durations. The script tries multiple machine learning models: Random Forest, Lasso regression, Ridge regression, LightGBM, XGBoost, and a Neural Network (MLP) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=def%20RFscore)) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=def%20Lightscore)). It uses `optuna` to tune hyperparameters for these models (with functions like `RFscore`, `Lassoscore`, etc., for Optuna trials) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=def%20RFscore)) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=import%20optuna)). The training procedure appears to use rolling or block-wise train-test splits of days (e.g., training on a set of days and testing on the next day in sequence) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=def%20process_data,i)) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=X_train%2C%20y_train1%2C%20y_train2%2C%20X_test%2C%20y_test1%2C,Xset%2C%20yset1%2C%20yset2%2C%20today_index%2C%20i)). It also records feature importance for the tree-based models and coefficients for linear models, which helps identify which predictors are most useful. To use this script, you may need to edit it to specify which stock’s data to train on (e.g., set the `stockname` variable or run a loop for multiple stocks). Then run:  
   ```bash
   python "Train copy calendar.py"
   ```  
   *(Note: the file name contains spaces, so quoting it or escaping spaces is necessary in the command.)* This will output model performance metrics (such as R² or classification accuracy) and possibly save results like feature importance. Check the console output and any files the script writes for the results on each stock.  
3. **Model Training and Evaluation (Event Time / Intraday Periodicity)** – **`periodic train.py`**:  
   This script likely complements the previous one by performing similar training and analysis in *transaction time* or focusing on intraday periods. The original study examined predictability on a **per-transaction basis** in addition to real time ([Movement of lower-priced stocks easier to predict for HFT firms, finds Princeton paper - IR Impact](http://www.ir-impact.com/2022/08/movement-lower-priced-stocks-easier-predict-hft-firms-finds-princeton-paper/#:~:text=Other%20factors%20also%20influence%20how,the%20accuracy%20of%20the%20predictions%E2%80%99)), and also studied how predictability might vary over the trading day (morning vs. midday vs. close) ([Movement of lower-priced stocks easier to predict for HFT firms, finds Princeton paper - IR Impact](http://www.ir-impact.com/2022/08/movement-lower-priced-stocks-easier-predict-hft-firms-finds-princeton-paper/#:~:text=Certain%20times%20of%20day%20%E2%80%93,something%20researchers%20term%20%E2%80%98intraday%20seasonality%E2%80%99)). The `periodic train.py` script probably loads the same processed data but might slice it by fixed numbers of trades or by intraday segments to analyze “periodic” effects. Running this script (`python "periodic train.py"`) will perform the analyses for these alternate setups. Again, ensure any required parameters (like stock name or data paths) are configured inside the script before execution.  
4. **Interpreting Output**: After running the above scripts, you will have results that can be compared to the findings of the paper. Look for printed output or log files that show things like prediction accuracy for returns, prediction accuracy for trade direction, R² for duration predictions, feature importance rankings, etc. These will allow you to verify the key outcomes – for example, how accuracy declines as the prediction horizon grows, or which features are most predictive.

**Example**: To replicate a full experiment for one stock, you might do:  
```bash
# Step 1: Construct features for stock 002352.XSHE (for example)
# (Make sure PreTrain.py is set to process the desired stock(s))
python PreTrain.py  

# Step 2: Train and evaluate models on calendar-time splits for that stock
python "Train copy calendar.py"  

# Step 3: Train and evaluate models on transaction-time or intraday segments
python "periodic train.py"  
```  
Monitor the output at each stage. The scripts might take a while to run, given the large volume of high-frequency data and the use of hyperparameter tuning. It’s recommended to start with a smaller subset of data (or fewer trials in optuna) to ensure everything works, then scale up to the full dataset for final results.

## Dataset Information  
**Data Sources**: The study relies on **tick-level data**, meaning every trade and quote update on an exchange order book. The original paper’s analysis used data from the NYSE/Nasdaq order books for the stocks in the S&P 100 index, covering January 2019 through December 2020 ([Movement of lower-priced stocks easier to predict for HFT firms, finds Princeton paper - IR Impact](http://www.ir-impact.com/2022/08/movement-lower-priced-stocks-easier-predict-hft-firms-finds-princeton-paper/#:~:text=For%20the%20research%2C%20the%20team,of%20March%20and%20April%202020%E2%80%99)). This included the highly volatile period of March–April 2020, allowing the researchers to test predictability in both normal and stressed market conditions ([Movement of lower-priced stocks easier to predict for HFT firms, finds Princeton paper - IR Impact](http://www.ir-impact.com/2022/08/movement-lower-priced-stocks-easier-predict-hft-firms-finds-princeton-paper/#:~:text=For%20the%20research%2C%20the%20team,of%20March%20and%20April%202020%E2%80%99)). In this replication repository, the code is configured to use data for the **HS300** stocks (the CSI 300 index, representing 300 large-cap stocks on the Shanghai and Shenzhen exchanges) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/README.md at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/README.md#:~:text=This%20repo%20is%20the%20replication,data%20on%20HS%20300%20stocks)). Specifically, tick data for year 2020 is mentioned in the code (e.g., file paths referencing `2020` directories) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/PreTrain.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/PreTrain.py#:~:text=files%20%3D%20os.listdir%28%22..%2F..%2Fdata%2FHFData%2FHS300_data%2F)).  

**Data Organization**: The tick data should be organized by stock and by date. For example, a likely structure (based on the code) is:  
```
data/HFData/HS300_data/<StockTicker>.<Exchange>/2020/<...files...>
```  
where `<StockTicker>.<Exchange>` might be something like `002352.XSHE` (stock code and exchange suffix) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/PreTrain.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/PreTrain.py#:~:text=files%20%3D%20os.listdir%28%22..%2F..%2Fdata%2FHFData%2FHS300_data%2F)). Each daily file would contain the sequence of trades and quotes for that stock on that date. The code reads these files to build a continuous history of events. Make sure to adjust the path if your data is stored differently, or alter the code to match your data location.  

**Data Fields**: Your tick data files should contain at least: timestamps, trade prices, trade sizes, quotes (bid price, ask price, bid size, ask size), and possibly identifiers for trade direction or order IDs. If the data doesn’t directly label trade direction (buyer- or seller-initiated trade), the code’s matching engine may infer it. In fact, the repository includes a `MatchingEngine` component ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/PreTrain.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/PreTrain.py#:~:text=from%20MatchingEngine%20import%20Engine)), which suggests it can reconstruct order book events (likely used to determine trade direction or simulate order matching). Ensure your data has the necessary information for the predictors, which include things like price changes, volumes, and order book imbalances (explained below).  

**Preprocessing**: The `PreTrain.py` script will handle most of the preprocessing: it loads raw data and computes the features and responses. This involves aligning trades and quotes in time and calculating rolling-window statistics at various horizons. One important preprocessing step is ensuring data quality – e.g., filtering out days with missing data or cleaning any bad ticks. The code concatenates daily data frames and drops any rows with non-finite values ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=trainset%3Dpd)) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=trainset%3Dtrainset)), so it is already handling basic cleaning. Just be sure your raw data is as complete as possible.  

**Output Data**: After preprocessing, the script produces a combined dataset `trainset` (likely a Pandas DataFrame) for each stock, with each row representing a specific event or time point (possibly the end of a prediction window) and columns for features and target variables. In the code, we see `trainset.iloc[:, :108]` used as features (X) and two target columns `iloc[:,108]` and `iloc[:,109]` as y (labeled `yset1` and `yset2`) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=Xset%3Dtrainset.iloc)) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=yset2%3Dtrainset.iloc)). This indicates there are 108 predictor features being calculated, and two outcomes: one could be the **future return** (price change over a short horizon) and the other the **duration** until the next event or price move. The index of `trainset` appears to be the date (or date-time) of each observation ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=yset2%3Dtrainset.iloc)) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=def%20process_data,i)). These processed data frames are saved (pickled) per stock per scenario (e.g., a “calendar” folder for time-based features). Users can reuse these pickles to avoid recomputation if running experiments multiple times.

## Methodology  
This project implements the methodology from the referenced paper, focusing on how to predict short-term price movements with high-frequency data and determining under what conditions such predictions are feasible. The key components of the methodology include:

- **Feature Engineering (Predictors)**: A rich set of predictors is constructed from the limit order book data. The code computes 13 base features over multiple short time windows ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/PreTrain.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/PreTrain.py#:~:text=Predictorlabel%3D)) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/PreTrain.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/PreTrain.py#:~:text=)). These features, drawn from market microstructure theory, include:  
  - *Breadth*: the difference in the number of trades on the bid vs. ask side (buy vs. sell pressure) over a window.  
  - *Immediacy*: a measure related to the urgency of trades (for instance, how quickly trades execute – possibly the inverse of waiting time or an indicator of very recent trades).  
  - *Volume (All/Avg/Max)*: total traded volume, average trade size, and maximum trade size in the window. These capture the level of activity and presence of large trades.  
  - *Lambda*: the intensity of trades or the hazard rate (commonly, λ in durations modeling indicates how quickly the next trade arrives).  
  - *LOB Imbalance*: order book imbalance – the difference between bid and ask depths (volume available) in the limit order book, indicating supply/demand skew.  
  - *Transaction Imbalance*: imbalance in the number of buyer-initiated versus seller-initiated trades.  
  - *Past Return*: the price return over the window (how much the price moved recently).  
  - *Turnover*: the fraction of shares (or dollar value) traded relative to the stock’s float or some benchmark, in that window.  
  - *AutoCov*: autocovariance of recent returns or sign of trades (captures momentum or mean-reversion tendencies in microprice movements).  
  - *Quoted Spread*: the bid-ask spread (difference between best ask and best bid prices) – a measure of liquidity and trading cost.  
  - *Effective Spread*: the effective spread paid in trades (related to trade price vs. mid-price, indicating price impact).  

  These 13 features are computed **across multiple time scales** – the paper uses exponentially increasing window sizes (e.g., 0–0.1 seconds, 0.1–0.2s, 0.2–0.4s, ... up to ~25.6s) for calendar time ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/PreTrain.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/PreTrain.py#:~:text=Predictorname.append%28Predictorlabel)), and similarly in **transaction time** (windows measured in number of trades). In the code, a list of time intervals `time_cal` defines the 9 windows for calendar time from 0.1s to 25.6s ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/PreTrain.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/PreTrain.py#:~:text=Predictorname.append%28Predictorlabel)). Each base feature is calculated for each window, resulting in up to 13 × 9 = 117 features (though it appears 108 are used, possibly excluding some combinations or due to multicollinearity filtering) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=Xset%3Dtrainset.iloc)). The feature names are concatenated with the window index (e.g., `Breadth0, Breadth1, ..., Immediacy0, ... EffectiveSpread8`) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/PreTrain.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/PreTrain.py#:~:text=Predictorlabel%3D)) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/PreTrain.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/PreTrain.py#:~:text=dict%3D%7BPredictorname%5B13)). This extensive feature set captures the state of the market in the moments leading up to each prediction point.  

- **Prediction Targets**: There are two main prediction targets studied – (1) the **short-term return** (price change) following a given moment, and (2) the **duration until the next event** (such as the next trade or quote change). In practice, the code’s `yset1` likely corresponds to the next *k*-second return or the indicator of price up/down movement, and `yset2` corresponds to the time until the next trade or next quote update ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=yset2%3Dtrainset.iloc)). The paper treated return prediction as both a regression (predicting the magnitude of return) and a classification (predicting the direction of the price move) problem, and duration as a regression (or classification of short vs. long wait). This code primarily sets them up as regression problems (using regressors like RandomForestRegressor, Lasso, etc., which output a numeric prediction) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=X_train%2C%20y_train1%2C%20y_train2%2C%20X_test%2C%20y_test1%2C,Xset%2C%20yset1%2C%20yset2%2C%20today_index%2C%20i)), but the direction can be inferred from the sign of the return prediction as well.  

- **Machine Learning Models**: A variety of machine learning models are applied to predict the outcomes from the features:  
  - **Lasso Regression** and **Ridge Regression**: linear models with L1 and L2 regularization, respectively. These are useful for high-dimensional data to perform feature selection (Lasso) or shrinkage (Ridge) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=def%20Lassoscore)) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=match%20at%20L918%20def%20Ridgescore)). The Lasso in particular can zero out uninformative features, helping identify which predictors matter most ([How and When are High-Frequency Stock Returns Predictable? by Yacine Ait-Sahalia, Jianqing Fan, Lirong Xue, Yifeng Zhou :: SSRN](https://doi.org/10.2139/ssrn.4095405#:~:text=Keywords%3A%20High,random%20forests%2C%20LASSO%2C%20penalized%20regression)).  
  - **Random Forests**: ensemble of decision trees, good for capturing nonlinear relationships and interactions. The code uses `RandomForestRegressor` from scikit-learn ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=clf_rf%3DRandomForestRegressor%28n_estimators%3D50%2Cmax_samples%3D0)). Random forests also provide feature importance measures, which the researchers can use to gauge the importance of each microstructure feature.  
  - **Gradient Boosted Trees**: the code includes LightGBM (`LGBMRegressor`) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=X_train%2C%20y_train1%2C%20y_train2%2C%20X_test%2C%20y_test1%2C,Xset%2C%20yset1%2C%20yset2%2C%20today_index%2C%20i)) and XGBoost (`XGBRegressor`) models, which are more advanced tree-based ensembles that often yield high predictive performance on structured data. These are also used to validate the robustness of findings across different model types.  
  - **Neural Network**: a Multi-Layer Perceptron regressor (`MLPRegressor` from scikit-learn) is used as a simple neural network model ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=match%20at%20L748%20from%20sklearn,import%20MLPRegressor)). This can capture complex nonlinear patterns, though with this many features, training an MLP might be challenging without careful tuning.  
  - **Others**: The mention of `RFscore`, `Lassoscore`, etc., in the code indicates an automated hyperparameter tuning routine (via Optuna) for Random Forest, Lasso, Ridge, LightGBM, XGBoost, and a neural net ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=def%20RFscore)) ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/Train copy calendar.py at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/Train%20copy%20calendar.py#:~:text=def%20get_best_param)). Each model’s hyperparameters (like number of trees, regularization strength, learning rate, etc.) are optimized on a validation set to ensure comparisons are fair and each model is as predictive as possible.

- **Experimental Design**: The study examines predictability over very short horizons. Concretely, it looks at predictions from a few milliseconds up to a few seconds ahead. The code reflects this by using the features described (which summarize up to ~25 seconds of recent data) to predict outcomes a short time ahead (likely the next 0.1s or next trade). The **timeliness of data** is explicitly studied: one experiment evaluates how predictive accuracy improves when using fresher data, measured in milliseconds ([How and When are High-Frequency Stock Returns Predictable? by Yacine Ait-Sahalia, Jianqing Fan, Lirong Xue, Yifeng Zhou :: SSRN](https://doi.org/10.2139/ssrn.4095405#:~:text=frequency%20returns%20and%20durations%20is,to%20the%20fastest%20high%20frequency)). For example, using data up to 10 milliseconds before the event vs. 1 second before can make a difference, which the code can simulate by adjusting feature windows or introducing a lag. Another analysis in the paper is the **“speed bump” experiment** – introducing an artificial processing delay (lag) to see how much predictive power is lost if your information is slightly stale ([Movement of lower-priced stocks easier to predict for HFT firms, finds Princeton paper - IR Impact](http://www.ir-impact.com/2022/08/movement-lower-priced-stocks-easier-predict-hft-firms-finds-princeton-paper/#:~:text=Other%20factors%20also%20influence%20how,the%20accuracy%20of%20the%20predictions%E2%80%99)). This essentially tests the value of speed in high-frequency trading. The code base could be adapted to simulate this by, say, shifting the alignment of features to mimic delayed data feeds.  

- **Intraday and Cross-Sectional Analysis**: The phrase “How and When” implies the study not only predicts returns but identifies when predictability is high or low. In practice, this involved:  
  - Splitting results by **stock characteristics**: The researchers found predictability varies with stock liquidity, volatility, and price level ([Movement of lower-priced stocks easier to predict for HFT firms, finds Princeton paper - IR Impact](http://www.ir-impact.com/2022/08/movement-lower-priced-stocks-easier-predict-hft-firms-finds-princeton-paper/#:~:text=predictable%3F%20www)). Less liquid, lower-priced stocks had more predictable short-term movements than highly liquid, high-priced ones ([Movement of lower-priced stocks easier to predict for HFT firms, finds Princeton paper - IR Impact](http://www.ir-impact.com/2022/08/movement-lower-priced-stocks-easier-predict-hft-firms-finds-princeton-paper/#:~:text=predictable%3F%20www)). The code can reproduce this by running the analysis on different groups of stocks or by including stock-specific attributes in the analysis.  
  - Examining **intraday patterns**: Predictability can change over the trading day. The paper reports an *intraday seasonality* in predictability – generally, the middle of the day and the very end of the day showed higher predictability of returns than the market open ([Movement of lower-priced stocks easier to predict for HFT firms, finds Princeton paper - IR Impact](http://www.ir-impact.com/2022/08/movement-lower-priced-stocks-easier-predict-hft-firms-finds-princeton-paper/#:~:text=Certain%20times%20of%20day%20%E2%80%93,something%20researchers%20term%20%E2%80%98intraday%20seasonality%E2%80%99)) ([Movement of lower-priced stocks easier to predict for HFT firms, finds Princeton paper - IR Impact](http://www.ir-impact.com/2022/08/movement-lower-priced-stocks-easier-predict-hft-firms-finds-princeton-paper/#:~:text=%E2%80%98Interestingly%2C%20predictability%20at%20the%20end,are%20more%20consistent%20across%20days%E2%80%99)). To study this, one might modify the code to train/test models separately on different time-of-day slices (morning session vs. afternoon vs. closing auction). The provided code `periodic train.py` likely facilitates some of this analysis, perhaps by focusing on periodic intervals or by tagging data points by their intraday time and evaluating performance within those segments.  

- **Validation**: The performance of each model is measured to confirm that high-frequency returns can indeed be predicted better than chance. For classification (predicting price *direction* up or down), accuracy is the metric; for regression (predicting return magnitude or duration), R² or MSE are used. In the high-frequency domain, even a slight edge (e.g., 60% directional accuracy vs. 50% random) is significant. The code prints or logs these metrics for each model and each scenario. The research found that all models generally confirm a strong predictability at very short horizons, though nonlinear models (like random forests) captured slightly more complex effects. By replicating these with the code, one should observe that certain features (like order imbalance or recent returns) consistently get high importance and that the predictability is statistically significant in out-of-sample tests.

In summary, the methodology combines *detailed feature engineering from market microstructure* with *modern ML models and rigorous cross-validated testing* to assess the extent of predictability in high-frequency stock returns. By following the steps in this code, you will recreate the process of generating predictors from tick data and training models to see just **how much** information about the near-future price movement is embedded in the recent order flow.

## Results and Findings  
Reproducing the analysis with this code should yield results consistent with the key findings of Ait-Sahalia *et al.* (2022). Below is a summary of the major results and insights you can expect, which the README highlights for context:

- **Substantial Short-Run Predictability**: At a horizon of only a few seconds, stock price movements are far from random. The researchers demonstrated that with minimal model tuning, one can predict the **direction of the next price move over a 5-second window with about 63% accuracy**, significantly better than the 50% coin-flip benchmark ([Movement of lower-priced stocks easier to predict for HFT firms, finds Princeton paper - IR Impact](http://www.ir-impact.com/2022/08/movement-lower-priced-stocks-easier-predict-hft-firms-finds-princeton-paper/#:~:text=With%20%E2%80%98minimal%20algorithmic%20tuning%E2%80%99%2C%20HFT,frequency%20stock%20returns%20predictable)). This is a striking result, given that at longer horizons (minutes or days) such predictability largely disappears. The code’s output should show high classification accuracy or R² for very short horizons (e.g., 1–5 seconds).  

- **Predictability Decays with Time**: The predictive power is extremely short-lived. The study found that beyond roughly **5 minutes (or about 2,000 trades)**, the ability to forecast returns essentially vanishes – performance drops to near 50% accuracy (random chance) ([Movement of lower-priced stocks easier to predict for HFT firms, finds Princeton paper - IR Impact](http://www.ir-impact.com/2022/08/movement-lower-priced-stocks-easier-predict-hft-firms-finds-princeton-paper/#:~:text=across%20days%E2%80%99)). In other words, the market “memory” for these predictors is short; the immediate order flow contains predictive information, but after a few minutes, price changes become unpredictable. If you extend the prediction horizon in the code, you will likely observe a sharp decline in model performance as the horizon increases.  

- **Importance of the Most Recent Data**: The **most recent milliseconds of data carry most of the signal**. The authors note that about *80% of the overall predictability comes from the last 10 milliseconds or last 10 trades* before the prediction point ([Movement of lower-priced stocks easier to predict for HFT firms, finds Princeton paper - IR Impact](http://www.ir-impact.com/2022/08/movement-lower-priced-stocks-easier-predict-hft-firms-finds-princeton-paper/#:~:text=Other%20factors%20also%20influence%20how,the%20accuracy%20of%20the%20predictions%E2%80%99)). This means that features capturing the latest order book events (the last handful of trades or quote changes) are the most powerful predictors. The feature importance outputs in the replication should reflect this: predictors with very short windows (like 0–0.1s) will likely rank highest. This also implies diminishing returns for adding older data – including data from, say, 1 minute ago adds little to the prediction once you have the last few seconds.  

- **Effect of Delayed Data (Speed Lag)**: If there is even a small delay in processing data, predictive accuracy falls off sharply. The paper simulated a **“speed bump”** by adding an artificial delay to the information (similar to what the IEX exchange does with a 350µs delay) ([Movement of lower-priced stocks easier to predict for HFT firms, finds Princeton paper - IR Impact](http://www.ir-impact.com/2022/08/movement-lower-priced-stocks-easier-predict-hft-firms-finds-princeton-paper/#:~:text=This%20%E2%80%98speed%20bump%E2%80%99%20idea%20is,exchange%20itself%2C%E2%80%99%20says%20the%20exchange)). They found that even a slight lag significantly erodes the prediction accuracy ([Movement of lower-priced stocks easier to predict for HFT firms, finds Princeton paper - IR Impact](http://www.ir-impact.com/2022/08/movement-lower-priced-stocks-easier-predict-hft-firms-finds-princeton-paper/#:~:text=Other%20factors%20also%20influence%20how,the%20accuracy%20of%20the%20predictions%E2%80%99)). In practical terms, being 100ms behind the fastest traders can reduce your edge. This result underlines the value of speed in high-frequency trading. The replication code can test this by shifting feature windows or ignoring the last few milliseconds of data and checking how the model accuracy changes.  

- **Value of a Peek into Order Flow**: One of the most intriguing findings is quantifying the benefit of seeing incoming orders a bit in advance. The authors consider a hypothetical scenario where a trader gets an imperfect “peek” at the order flow shortly **before it reaches the market** (often speculated as an advantage of the fastest HFT firms). In their simulation, having this look-ahead roughly doubled the return predictability (R² from 14% to 27%) and improved trade direction accuracy from 68% to 79% ([Movement of lower-priced stocks easier to predict for HFT firms, finds Princeton paper - IR Impact](http://www.ir-impact.com/2022/08/movement-lower-priced-stocks-easier-predict-hft-firms-finds-princeton-paper/#:~:text=The%20paper%20also%20looks%20at,%E2%80%99)). In other words, even a small foresight of future orders hugely boosts prediction performance. The codebase could recreate this by incorporating future data as features (with caution: this is just to simulate the what-if scenario). This finding emphasizes how valuable any asymmetric speed advantage can be. *(The authors note they are not claiming such peeking ability definitely exists in the wild, just that if it did, it would be extremely profitable) ([Movement of lower-priced stocks easier to predict for HFT firms, finds Princeton paper - IR Impact](http://www.ir-impact.com/2022/08/movement-lower-priced-stocks-easier-predict-hft-firms-finds-princeton-paper/#:~:text=predictability%20from%2014%20percent%20to,%E2%80%99)).*  

- **Cross-Sectional Differences**: Predictability isn’t uniform across all stocks. It tends to be **higher for stocks that are lower-priced, less liquid, and more idiosyncratic**. The research specifically observed that smaller or less liquid stocks have more predictable short-term movements ([Movement of lower-priced stocks easier to predict for HFT firms, finds Princeton paper - IR Impact](http://www.ir-impact.com/2022/08/movement-lower-priced-stocks-easier-predict-hft-firms-finds-princeton-paper/#:~:text=predictable%3F%20www)). These stocks likely have fewer arbitrageurs and may respond more slowly to information, leaving brief opportunities to predict their moves. In contrast, extremely liquid stocks (think large tech companies) are so heavily traded that any pattern is arbitraged away almost instantly, yielding lower predictability. If you run the code on different stocks, expect to see variation in accuracy – the repository’s focus on HS300 (Chinese market) might reveal similar patterns (some mid-cap A-shares being more predictable than the biggest, most liquid ones).  

- **Intraday Variations**: There is a notable **intraday pattern** in predictability. Despite higher volatility at market open and close, the study found the *middle of the day* was actually easier to predict returns than the open, and the **end-of-day had the highest predictability of all** ([Movement of lower-priced stocks easier to predict for HFT firms, finds Princeton paper - IR Impact](http://www.ir-impact.com/2022/08/movement-lower-priced-stocks-easier-predict-hft-firms-finds-princeton-paper/#:~:text=Certain%20times%20of%20day%20%E2%80%93,something%20researchers%20term%20%E2%80%98intraday%20seasonality%E2%80%99)) ([Movement of lower-priced stocks easier to predict for HFT firms, finds Princeton paper - IR Impact](http://www.ir-impact.com/2022/08/movement-lower-priced-stocks-easier-predict-hft-firms-finds-princeton-paper/#:~:text=%E2%80%98Interestingly%2C%20predictability%20at%20the%20end,are%20more%20consistent%20across%20days%E2%80%99)). The consistency of trading patterns later in the day (possibly due to routine liquidity provision or end-of-day order flow patterns) might make the closing period more amenable to prediction, even though volatility is elevated. The replication code, if segmented by time, should show that models perform best on data from the final trading interval of the day, and worst during the first half-hour of trading (when the market incorporates overnight news with bursts of volatility). This insight is somewhat counter-intuitive and underscores that predictability is not solely about volatility magnitude.  

Overall, the findings portray a nuanced picture: **yes, high-frequency stock returns are predictable**, but the predictability is localized to very short horizons and certain conditions. If you use this code and dataset to replicate the experiments, your results should echo these points – high accuracy for immediate predictions that rapidly attenuates, and clear differences across stocks and times of day. The takeaway is that the microstructure of markets (order flow, liquidity, etc.) does allow short-term forecasting, aligning with the idea that market efficiency is not absolute at the millisecond level ([EconPapers: How and When are High-Frequency Stock Returns Predictable?](https://econpapers.repec.org/RePEc:nbr:nberwo:30366#:~:text=returns%20and%20durations%20to%20relevant,data%20on%20a%20scale%20of)), but this predictability has strict limits in time and scope.

*(For detailed numeric results and tables, please refer to the original paper. The above points are highlights and the code will allow you to compute these statistics for the dataset in use.)*

## Contributors  
This repository’s code was developed by **Fanyi Yang** (GitHub user *fanyiyang*), who created it as a replication of the high-frequency predictability study ([How-and-When-are-High-Frequency-Stock-Returns-Predictable/README.md at main · fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable · GitHub](https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable/blob/main/README.md#:~:text=This%20repo%20is%20the%20replication,data%20on%20HS%20300%20stocks)). The original research was conducted by Yacine Aït-Sahalia, Jianqing Fan, Lirong Xue, and Yifeng Zhou – they are the authors of the paper *“How and When are High-Frequency Stock Returns Predictable?”* (2022) ([EconPapers: How and When are High-Frequency Stock Returns Predictable?](https://econpapers.repec.org/RePEc:nbr:nberwo:30366#:~:text=Yacine%20Ait,Xue%20and%20Yifeng%20Zhou)). While the authors provided the conceptual framework and analysis, this GitHub project by Fanyi Yang re-implements the methodology (possibly as part of an academic project or research assistance) on a different dataset (HS300 stocks).

**How to Contribute**: If you would like to contribute to this repository, you can fork the project and submit pull requests. Contributions might include improving code efficiency, adding documentation, or adapting the code for other markets or extended analyses. Before contributing, it may be useful to open an issue in the repository’s Issues tab to discuss your planned changes (if the repository is actively maintained). As this code is a research replication, extensions could involve: integrating new data sources, adding more prediction models, or updating the code for newer versions of libraries. Contributors should ensure any changes remain consistent with the methodology and note differences if results are affected.

We also encourage users of this code to credit both this repository’s maintainer and the original authors of the paper in any derivative works or publications. See the **References and Citation** section below for the appropriate citation. For questions or support with the code, you might try contacting the repository owner via GitHub or checking if they have provided an email/contact in the repo or their profile.

## License  
*No explicit license is provided in this repository.* As of the latest update, there is no LICENSE file or statement, which typically means **all rights are reserved** by default. The code is provided as-is for replication and educational purposes. If you plan to use or modify this code for your own research or a project, especially commercially, you should proceed with caution:

- **Research and Academic Use**: It’s generally acceptable to use and adapt the code for non-commercial academic research, but be sure to give credit to the original author (this repo’s contributor) and the paper’s authors. Cite the paper when publishing any results that build on this work (see below).  
- **Commercial Use**: Without a license, you do *not* have explicit permission to use the code in commercial applications. If that is your intention, consider reaching out to the repository owner for permission.  
- **Adding a License**: If you are the owner or have forked the project, you might consider adding an open-source license (such as MIT or Apache-2.0) to clarify usage rights. In absence of that, assume the default (restrictive) copyright.

Always respect the original intellectual contributions: the code replicates a published methodology, so any reuse should include proper attribution. When in doubt, contact the author for clarification. 

## References and Citation  
If you use the code or findings of **“How and When are High-Frequency Stock Returns Predictable?”** in your work, please cite the original paper by Aït-Sahalia *et al.*. Below is the reference information:

- Yacine Aït-Sahalia, Jianqing Fan, Lirong Xue, and Yifeng Zhou (2022). **“How and When are High-Frequency Stock Returns Predictable?”** NBER Working Paper No. 30366 ([EconPapers: How and When are High-Frequency Stock Returns Predictable?](https://econpapers.repec.org/RePEc:nbr:nberwo:30366#:~:text=Yacine%20Ait,Xue%20and%20Yifeng%20Zhou)) ([EconPapers: How and When are High-Frequency Stock Returns Predictable?](https://econpapers.repec.org/RePEc:nbr:nberwo:30366#:~:text=Abstract%3A%20This%20paper%20studies%20the,data%20on%20a%20scale%20of)). *(Also available as an SSRN Electronic Journal preprint.)* 

In BibTeX format (if needed for academic writing):  
```bibtex
@techreport{AitSahalia2022HighFreqPredictable,
  title={{How and When are High-Frequency Stock Returns Predictable?}},
  author={Ait-Sahalia, Yacine and Fan, Jianqing and Xue, Lirong and Zhou, Yifeng},
  year={2022},
  institution={National Bureau of Economic Research},
  type={NBER Working Paper},
  number={30366},
  note={Available at SSRN: \url{https://ssrn.com/abstract=4095405}}
}
```  
This citation covers the theoretical framework and original findings that this repository’s code is based on. 

Additionally, if referring to the replication code, you might cite this GitHub repository (e.g., in a footnote or appendix) as: *“Fanyi Yang (2022), replication code for ‘How and When are High-Frequency Stock Returns Predictable?’ available at https://github.com/fanyiyang/How-and-When-are-High-Frequency-Stock-Returns-Predictable.”* 

**References in context**: The key insights summarized in this README are drawn from the authors’ analysis and conclusions in the paper. For example, the 63% directional accuracy and higher predictability for less liquid stocks are documented by Roach (2022) summarizing Aït-Sahalia *et al.* ([Movement of lower-priced stocks easier to predict for HFT firms, finds Princeton paper - IR Impact](http://www.ir-impact.com/2022/08/movement-lower-priced-stocks-easier-predict-hft-firms-finds-princeton-paper/#:~:text=With%20%E2%80%98minimal%20algorithmic%20tuning%E2%80%99%2C%20HFT,frequency%20stock%20returns%20predictable)) ([Movement of lower-priced stocks easier to predict for HFT firms, finds Princeton paper - IR Impact](http://www.ir-impact.com/2022/08/movement-lower-priced-stocks-easier-predict-hft-firms-finds-princeton-paper/#:~:text=predictable%3F%20www)), and the effect of a peek at order flow is described in the paper’s simulation results ([Movement of lower-priced stocks easier to predict for HFT firms, finds Princeton paper - IR Impact](http://www.ir-impact.com/2022/08/movement-lower-priced-stocks-easier-predict-hft-firms-finds-princeton-paper/#:~:text=The%20paper%20also%20looks%20at,%E2%80%99)). These citations are included inline to guide readers to the source of each claim. For a deeper understanding or additional background (such as prior literature on market microstructure used in the paper), please refer to the references listed in the original paper ([How and When are High-Frequency Stock Returns Predictable?](https://ouci.dntb.gov.ua/en/works/4LgM0qV7/#:~:text=List%20of%20references)) ([How and When are High-Frequency Stock Returns Predictable?](https://ouci.dntb.gov.ua/en/works/4LgM0qV7/#:~:text=7,10016)).

By citing the work properly, you acknowledge the contributions of the researchers and help others find the original source for more details. Happy researching with high-frequency data!
